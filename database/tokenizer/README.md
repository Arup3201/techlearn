# Tokenizer

A compiler has tokenizer to break the source code into small meaningful parts that can be processed. There are some terms like `token`, `lexeme` and `pattern`.

- `token`: It is the a category like keywords, identifiers etc which has some meaning and are the smallest unit of the source code.
- `pattern`: It is the structure that matches with the token.
- `lexeme`: It is the actual sequence of characters that matches a token's pattern.

In programming language, tokens are the smallest meaningful units that cannot be decomposed further. In languages like C, tokens can be `keywords`, `identifiers`, `operators` and `delimiters` (comma, semi-colon, braces etc.).

Tokens may be divided into 3 categories -

1. Terminal symbols - keywords and operators.
2. Literals - variables like numbers and strings.
3. Identifiers - user defined names.


